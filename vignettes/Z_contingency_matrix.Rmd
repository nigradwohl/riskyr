---
title: "Contingency Matrix"
author: "SPDS, uni.kn"
date: "2018 04 16"
output: 
  rmarkdown::html_vignette: 
    fig_caption: yes
vignette: >
  %\VignetteIndexEntry{Confusion Matrix and Metrics}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)

library("riskyr")  # load the "riskyr" package
```

## Goal

Generalize the 2x2 confusion matrix (framed in the semantics of SDT and clinical diagnostics) to different types of contingency tables (e.g., to also represent effects of treatments, RCTs, or preventive measures). 

## Terminology

The following "contingency matrix"" is a generalization of the "confusion matrix":

|              | 'cols' |          |       |          |        |       
| ------------:  |:--------:|:--------:|:--------:|:--:|:---------:|              
| `rows` | c1 (`TRUE`):      | c2 (`FALSE`):     |     Sum:  |  (b) column 1 by row: |  (b) column 2 by row | 
| r1 (`TRUE`):      | `r1c1`  | `r1c2`         | `n_r1` | `pr_r1c1` = `r1c1`/`n_r1`  | `pr_r1c2` = `r1c2`/`n_r1` |
| r2 (`FALSE`):  | `r2c1`  | `r2c2`         | `n_r2` | `pr_r2c1` = `r2c1`/`n_r2`     | `pr_r2c2` = `r2c2`/`n_r2` |
|      Sum:          | `n_c1`   | `n_c2`          | `N`   | `p_c1` =  `n_c1`/`N`     | `p_c2` =  `n_c2`/`N` |
| (a) row 1 by column | `pc_r1c1` = `r1c1`/`n_c1` | `pc_r1c2` = `r1c2`/`n_c2` | `p_r1` = `n_r1`/`N` |  `rc12` = `diag`/`N` = (`r1c1`+`r2c2`)/`N`|
| (a) row 2 by column | `pc_r2c1` = `r2c1`/`n_c1` | `pc_r2c2` = `r2c2`/`n_c2` | `p_r2` = `n_r2`/`N` | | |


The following properties hold for this table: 

* For frequencies, (i.e., the inner three rows and columns):
    + if at least any two entries in a row or column are provided, all values in _this_ row or column can be
    calculated. 
    + As soon, as there are three values in one row or column, there is redundancy, and more input is needed. 
    + At least three different cells need to be in a row or column with two filled cells in this row or column 
    (kind of an s-shape). 
    
  This can be used to test frequency entries for completeness. 

* For probabilities (N is normed to 1):
    + probabilities in one row or column are not independent, and thus do not add up to 1. 
    + The probabilities derived from the margins (unconditional probabilities p_c1, p_r1 and their inverse) 
    add up to 1. 
    
    + probabilities obey a 2x2 table for N = 1.  This table can be multiplied by any N to obtain frequencies. 
    + As they are probabilities N is known to be 1 by __definition__. 
    + The probabilities seem to be non-redundant, if three cells can be calculated directly from the input (just 
    as with frequencies) 
    + This only holds for cell probabilities; not for the conditional ones; it seems to reproduce Bayes' theorem 
    in a sense 
    + This tells us that one cell probability (p(A&B)) and two unconditional probabilities can be sufficient 
    (e.g., n_c1, N, p_r1, P_c1, should suffice).  this is also the case, if instead of one cell frequency a 
    conditional probability is provided (as then the cell frequency can be computed from N, and the cell 
    probability can be calculated). 


Note that the probabilities in the margins follow `nrow_prob == nrow_freq - 1` and `ncol_prob == ncol_freq - 1` (ignoring cases with partial cell sums like `r1c1 + r1c2 / r1c1 + r1c2 + r1c3`). 

* For a 2x2 table (probably generalizes): If one can calculate all probabilities (accuracy is not necessary) and __any__ frequency, the table is fully defined.  All probabilities can be calculated when :
    + one has two conditional probabilities and the corresponding unconditional probability (if you have the row probabilities you need the unconditional probabilities to be in a certain row; e.g., PPV, NPV, and ppod)  
    + one has two unconditional probabilities and any conditional probability (setting $N = 1$ allows to calculate all relative sums and relative frequencies; having one frequency allows to calculate $N$, as relative cell frequencies are defined by $cell frequency/N$, and thus: $N = cell frequency/relative cell frequency$; the rest is trivial). 
    
* For frequencies one needs at least 2 occupied cells in both dimensions plus one additional non-redundant cell (e.g., hi+mi and dec.neg+N or hi+fa+cr+N OR hi+mi+cond.false+N+any of the remaining).  

```{r}
## An example table: 
complete_freq <- rbind(c(17, 25),
                      c(28, 30)
                      )
    ## Sums (frequency table):
    complete_freq <- cbind(complete_freq, rowSums(complete_freq))
    complete_freq <- rbind(complete_freq, colSums(complete_freq))

    rel_freq <- complete_freq / complete_freq[dim(complete_freq)[1], dim(complete_freq)[2]]

    ## Probs:
      p_row <- t(apply(complete_freq, 1, function(X) X/X[3]))[,1:2]
      p_col <- apply(complete_freq, 2, function(X) X/X[3])[1:2, ]

    ## Complete table (freqs and probs):
      complete_tab <- cbind(complete_freq, p_row)  # add the row probabilities.
      complete_tab <- rbind(complete_tab, cbind(p_col, NA, NA))
      complete_tab[4, 4] <- (complete_tab[1, 1] + complete_tab[2, 2]) / complete_tab[3, 3]
      complete_tab


    ## Relative frequency table:
      tab_rel <- cbind(rel_freq, p_row)
      tab_rel <- rbind(tab_rel, cbind(p_col, NA, NA))
      v_diag <- diag(tab_rel)  # use instead of below statements.
      dix <- which(is.na(v_diag))[1]  # index value for diagonal (symmertric table only).
      vals_diag <- v_diag[!is.na(v_diag)]  #exclude NA-values.
      nmrtr <- vals_diag[1:(length(vals_diag) - 1)]  # exclude last element (N) to obtain numerator.
      tab_rel[dix, dix] <- (sum(nmrtr)) / vals_diag[length(vals_diag)]
      tab_rel

    ## assign to x:
    x <- complete_tab
    
## Showing the examples: 
    
```


* Probably, if you can generate one of the two above cases by a mixture, then it works out as well: e.g., PPV instead of hits and ppod instead of N.  You could replace any frequency by a probability that includes this frequency. 

* It may be even more general, that any two pairs of non-redundant inputs is sufficient.  But what does non-redundancy mean? 
    + ??? 

__Potential implementations__

* Ask for each cell, wheter one of the defining equations can be solved 
* Find a condition that accounts for calculability 

### Use R-code to create the respective input-table (label-tabels):

#### Create frequency table: 

```{r create_terminology_matrix_freq}
## define rows with frequencies (table extent), example 2x2:
n_row <- 2
n_col <- 2

# get the single frequencies:
row_lab <- paste0("r", 1:n_row)
col_lab <- paste0("c", 1:n_col)

freq_labs <- expand.grid(row_lab, col_lab)
freq_mat <- matrix(paste0(freq_labs[, 1], freq_labs[, 2]), ncol = n_col, nrow = n_row)

# get labels for the sums:
rowsum_lab <- paste0("n_r", 1:n_row)
colsum_lab <- c(paste0("n_c", 1:n_col), "N")  # add N in the end. 

## (1) Assemble prelimnary table:
freq_mat <- cbind(freq_mat, rowsum_lab, deparse.level = 0)
freq_mat <- rbind(freq_mat, colsum_lab, deparse.level = 0)
freq_mat

## (2) Adding the probabilities:
```

Showing the table as `kable`

```{r show_table_freq, results='asis'}
colnames(freq_mat) <- c(paste0("col", 1:n_col), "Sum")
rownames(freq_mat) <- c(paste0("row", 1:n_row), "Sum")
  
knitr::kable(freq_mat)
```


Showing the table as figure 

```{r show_table_freq_fig}

## Get plot dimensions: 
plot_dim <- dim(freq_mat) + 1

## Initialize plot of respective size: 
margin <- 0.2  # set a margin around the entries.

plot(x = 1, xlim = c(1 - margin, plot_dim[1] + margin), ylim = c(1 - margin, plot_dim[2] + margin),
     type = "n",
     xaxt = "n", xlab = "",
     yaxt = "n", ylab = ""
     )

## Get coordinates
coords <- expand.grid(x = 1:plot_dim[1], y = plot_dim[2]:1)

## Get corresponding entries:
entries <- c("", colnames(freq_mat),
             c(apply(cbind(rownames(freq_mat), freq_mat), 1, c))  # convet into rows.
             )

## Set headings in boldface:
headings <- ifelse(coords$x == 1 | coords$y == 4, 2, 1)

# Create table with coordinates and entries:
coo_ent <- cbind(coords, entries, headings)

## Add text:
text(x = coo_ent$x, y = coo_ent$y, labels = coo_ent$entries, font = headings)

## Add lines:
# grid(nx = plot_dim[1], ny = plot_dim[2],
#      col = "black", lty = 1)

abline(v = 1:3 + margin)
abline(h = 1:3 + 0.5)
```

Can be made prettier but does already work fine. 


#### Generating the full table

```{r create_terminology_matrix_full}
## define rows with frequencies (table extent), example 2x2:
fn_row <- 2
fn_col <- 2

## get the single frequencies:
row_lab <- paste0("r", 1:fn_row)
col_lab <- paste0("c", 1:fn_col)

freq_labs <- expand.grid(row_lab, col_lab, stringsAsFactors = FALSE)
freq_mat <- matrix(paste0(freq_labs[, 1], freq_labs[, 2]), ncol = n_col, nrow = n_row)

## get labels for the sums:
rowsum_lab <- paste0("n_r", 1:fn_row)
colsum_lab <- c(paste0("n_c", 1:fn_col), "N")  # add N in the end. 

## get labels for the probabilities:
pr_labs <- rbind(matrix(paste0("pr_", freq_mat), ncol = 2), paste0("p_c", 1:fn_row))  # rowwise.
pc_labs <- cbind(matrix(paste0("pc_", freq_mat), ncol = 2), paste0("p_r", 1:fn_row))  # colwise.
pc_labs <- cbind(pc_labs, matrix(c("rc12", rep(NA, 3)), nrow = fn_row))

## (1) Assemble prelimnary table:
freq_mat <- cbind(freq_mat, rowsum_lab, deparse.level = 0)
freq_mat <- rbind(freq_mat, colsum_lab, deparse.level = 0)
freq_mat <- cbind(freq_mat, pr_labs)
freq_mat <- rbind(freq_mat, pc_labs)
freq_mat

## (2) Adding the probabilities:
```

Showing the table as `kable`

```{r show_table_full, results='asis'}
colnames(freq_mat) <- c(paste0("col", 1:n_col), "Sum", paste0("c", 1:n_col, "br"))
rownames(freq_mat) <- c(paste0("row", 1:n_row), "Sum", paste0("r", 1:n_col, "bc"))

freq_mat[is.na(freq_mat)] <- ""
  
knitr::kable(freq_mat)
```


Showing the table as figure 

```{r show_table_full_fig}

## Get plot dimensions: 
plot_dim <- dim(freq_mat) + 1

## Initialize plot of respective size: 
margin <- 0.2  # set a margin around the entries.

plot(x = 1, xlim = c(1 - margin, plot_dim[1] + margin), ylim = c(1 - margin, plot_dim[2] + margin),
     type = "n",
     xaxt = "n", xlab = "",
     yaxt = "n", ylab = ""
     )

## Get coordinates
coords <- expand.grid(x = 1:plot_dim[1], y = plot_dim[2]:1)

## Get corresponding entries:
entries <- c("", colnames(freq_mat),
             c(apply(cbind(rownames(freq_mat), freq_mat), 1, c))  # convet into rows.
             )

## Set headings in boldface:
headings <- ifelse(coords$x == 1 | coords$y == max(coords$y), 2, 1)

# Create table with coordinates and entries:
coo_ent <- cbind(coords, entries, headings)

## Add text:
text(x = coo_ent$x, y = coo_ent$y, labels = coo_ent$entries, font = headings)

## Add lines:
# grid(nx = plot_dim[1], ny = plot_dim[2],
#      col = "black", lty = 1)

abline(v = 1:(plot_dim[1] - 1) + 0.5)
abline(h = 1:(plot_dim[2] - 1) + 0.5)
```


### Conditions:

#### Necessary 

* At least four inputs (N may be arbitrarily set)

#### Sufficient 


### JS Applet

[http://jumbo.uni-muenster.de/fileadmin/jumbo/applets/vierf.html]

[https://www.funky-bits.de/roc-curve-online-calculator-analysis-interactive-diagram/] 


### Recursive solution 

```{r example_table}
## Example table: 
complete_freq <- rbind(c(17, 25),
                      c(28, 30)
                      )
    ## Sums (frequency table):
    complete_freq <- cbind(complete_freq, rowSums(complete_freq))
    complete_freq <- rbind(complete_freq, colSums(complete_freq))

    rel_freq <- complete_freq / complete_freq[dim(complete_freq)[1], dim(complete_freq)[2]]

    ## Probs:
      p_row <- t(apply(complete_freq, 1, function(X) X/X[3]))[,1:2]
      p_col <- apply(complete_freq, 2, function(X) X/X[3])[1:2, ]

    ## Complete table (freqs and probs):
      complete_tab <- cbind(complete_freq, p_row)  # add the row probabilities.
      complete_tab <- rbind(complete_tab, cbind(p_col, NA, NA))
      complete_tab[4, 4] <- (complete_tab[1, 1] + complete_tab[2, 2]) / complete_tab[3, 3]
      complete_tab

ex_tab <- complete_tab

## Remove some entries:
ex_tab <- ex_tab[1:3, 1:3]  # frequencies only.
  
  ## Version 1:
  ex_tab[2, ] <- NA
  ex_tab[, 2] <- NA
  
  ## Version 2:
  ex_tab[2, ] <- NA
  ex_tab[3, 2] <- NA
  ex_tab[1, 3] <- NA

  ## version 3:
  ex_tab[c(2,3), 2] <- NA
  ex_tab[3, 2] <- NA
  ex_tab[1, 3] <- NA
  
  ## Version 4 (should not work):
  ex_tab[c(1, 1, 3, 3), c(1, 3, 1, 3)] <- NA
  ex_tab[2, 2] <- NA
  
  ## Version 5:
  ex_tab[2, ] <- NA
  ex_tab[1, 2] <- NA
  ex_tab[3, 1] <- NA
  
  ## Version 6: 
  ex_tab[1:3, 3] <- NA
  
  ## Version 7: (should need the recursion!)
  
## Testing with probabilities:
exp_tab <- complete_tab
exp_tab[1, c(2, 3)] <- NA
exp_tab[c(2, 4), c(5, 2)] <- NA

  ## Note, one frequency and one probability are necessary and sufficient to calculate a row or column.

calc_tab(ex_tab)
```


```{r recursive_function}
## For frequency part:
table <- ex_tab  

table <- exp_tab
table  # show table for checking reasons:

## Function for recursive calculation: 
calc_tab <- function(table) {
  
  ## Get the dimensions:
  n_row <- nrow(table)
  n_col <- ncol(table)
  
  ## TODO: Clarify, whether to include both in one function or have separate functions for freqs and probs.
  
  ## (A) Calculate frequencies from frequencies: -----
  
    ## (1) Check for rows and columns that can be calculated: -----
    ## Logical index matrix for NA values: 
    mf_na_log <- is.na(table)  # get matrix of NAs for the frequency case. 
  
    ## Stopping point 1:
    if (!any(mf_na_log)) {
      return(table)  # return, when table is complete. 
    }
  

    ## (a) Rows: -----
      ## Get indices of rows that can be calculated:
      rcalc_ix <- which(rowSums(mf_na_log) == 1)  # get rows with exactly one NA (can be calculated). 

      ## Sum up values in the indexed rows except their sum in the last column: 
      m_rf <- matrix(table[rcalc_ix, -n_col], ncol = n_col - 1)  # matrix of calculable frequency rows. 
      rsums <- rowSums(m_rf, na.rm = TRUE)  # rowsums to be inserted into cells. 
    
      ## Test, which operation to perform: 
      
        ## Test for empty sum columns in the calculable rows:
        rsum_na_lc <- is.na(table[rcalc_ix, n_col])   # which of the calculable rows is NA in the last column? 
        
        if (any(rsum_na_lc)) {
          ## Insert the sums in the last column for the rows with NAs:
          table[rcalc_ix, n_col][rsum_na_lc] <- rsums[rsum_na_lc]
        } 
        
        ## Test, if there is any row in which the empty cell is not a row sum:
        if (any(!rsum_na_lc)) {  

          ## Check, which columns in the identified rows are NA:
          rows_na <- rcalc_ix[!rsum_na_lc]
          rows_na_m <- matrix(table[rows_na, ], ncol = n_col)  
          ## get the rows with NAs not in last position. 
          
          ## Calculate values for insertion:
          vals_row <- rows_na_m[, n_col] - rsums[!rsum_na_lc]
          
          tab <- t(rows_na_m)  # transpose table, as columns are filled first. 
          cellr_ix <- which(is.na(tab), arr.ind = TRUE)  # index for the cells without entries. 

          ## Insert the values:
          tab[cellr_ix] <- vals_row
          table[rows_na, ] <- t(tab)  # retranspose and reassign. 

        }

      
    ## (b) Columns: -----
      ## Renew log_na:
      mf_na_log <- is.na(table)  # get matrix of NAs
        
        ## TODO: Allow to stop hera as well? 
        
      ## Get indices of columns that can be calculated:
      ccalc_ix <- which(colSums(mf_na_log) == 1)  # get columns with exactly one NA (can be calculated). 
    
      ## Sum up values in the indexed columns except their sum in the last row: 
      m_cf <- matrix(table[-n_row, ccalc_ix], nrow = n_row - 1)
      csums <- colSums(m_cf, na.rm = TRUE)
      
      ## Test, which operation to perform: 
        ## Test for empty sum rows in the calculable columns:
        csum_na_lr <- is.na(table[n_row, ccalc_ix])  # which of the rows is NA in the last column? 
        
        if (any(csum_na_lr)) {
          ## get index for the columns in which the last row is empty. 
          table[n_row, ccalc_ix][csum_na_lr] <- csums[csum_na_lr]
          ## Assign appropriate values. 
        } 
        
        ## Test, if there is any row in which the empty cell is not a row sum:
        if (any(!csum_na_lr)) { 
          
          ## Check, which rows in the identified columns are NA:
          cols_na <- ccalc_ix[!csum_na_lr]
          cols_na_m <- matrix(table[, cols_na], nrow = n_row)  
          ## get the columns with NAs not in last position. 
          cellc_ix <- which(is.na(cols_na_m), arr.ind = TRUE)  # index for the cells without entries. 
          
          vals_col <- cols_na_m[n_row, ] - csums[!csum_na_lr]
          table[, cols_na][is.na(table[, cols_na])] <- vals_col
          
        }
        
        
    ## XX: Return statement and stopping rules: --------
      mf_na_log <- is.na(table)  # get matrix of NAs after one run. 
      
      ## Recursive STOPPING rule 1:
      if (!any(mf_na_log)) {
        return(table)  # return, when table is complete. 
        
      ## STOPPING RULE 2:
      } else if(!any(rowSums(mf_na_log) == 1 | colSums(mf_na_log) == 1)) {  
        ## if no single value in neither dimension. 
        
        stop("The information you specified is not sufficient to calculate the table.\n
              I need at least one more value."
                    )
      
      ## CONTINUE:  
      } else {
        
        return(calc_tab(table))
      }
        
        
        
        # TODO: Perform consistency checks or update NA-matrix in between steps?
        # TODO: Provide an informative error message upon insufficient inputs. 
    
  ## (B) Include probabilities: ------
    ## (1) Calculate all possible probabilities (see above?): ------
      ## (a) Mute the frequency proportion:
      ptab <- table

      ## Set the dimensions of the frequency part:
      frow <- 3
      fcol <- 3
        ## This may be done dynamically in the future.
        ## TODO!
      ptab[1:frow, 1:fcol] <- NA  # mute the frequency part.

      ## Bayes rule: P(A|B) = (P(B|A) * P(A)) / P(B)

      ## (a) Calculate all complements: ------

        ## Checking for completeness:
        mp_r <- ptab[1:frow, -(1:fcol)]  # matrix of probabilities calculated from rows.
        mp_r_na_log <- is.na(mp_r)
        mp_c <- ptab[-(1:frow), 1:fcol]  # matrix of probabiilities calculated from columns.
        mp_c_na_log <- is.na(mp_c)

        pr_inc <- any(mp_r_na_log)  # check rows.
        pc_inc <- any(mp_c_na_log)  # check cols.

        if (!any(c(pr_inc, pc_inc))) # TODO: this is a stopping condition for the probabilitiy case.

        ## Calculate compelemets for rows: -----
        if(pr_inc) {  # if row elements are missing.

          row_na <- which(rowSums(mp_r_na_log) == 1)  # get rows with NA-values.
          rmat_na <- matrix(mp_r[row_na, ], ncol = ncol(mp_r))  # convert into matrix (to allow rowsums).
          ## Complete row matrix:
          mp_r[row_na, mp_r_na_log[row_na, ]] <- 1 - rowSums(rmat_na, na.rm = TRUE)

          ## Check summing up to one:
            rows_eq1 <- rowSums(mp_r) == 1

            ## Warn (or provide error, if they do not):
            if(any(!rows_eq1)) warning(paste0("Probabilities in row ", which(!rows_eq1), " do not sum up to 1."))

          ## Include into original table:
            ptab[1:frow, -(1:fcol)] <- mp_r
        }


        ## Calculate compelemets for columns: ------
        if (pc_inc) {  # if column elements are missing.

          col_na <- which(colSums(mp_c_na_log) == 1)  # get cols with NA-values.
          cmat_na <- matrix(mp_c[, col_na], nrow = nrow(mp_c))  # convert into matrix (to allow colsums).
          ## Complete column matrix:
          mp_c[mp_c_na_log[, col_na], col_na] <- 1 - colSums(cmat_na, na.rm = TRUE)

          ## Check summing up to one:
            cols_eq1 <- colSums(mp_c) == 1

            ## Warn (or provide error, if they do not):
            if(any(!comp_col)) {
              warning(paste0("Probabilities in column ", which(!cols_eq1), " do not sum up to 1.\n"))
            }

          ## Include into original table:
            ptab[-(1:frow), 1:fcol] <- mp_c
        }

      ## Reassemble tables:
        table[!is.na(ptab)] <- ptab[!is.na(ptab)]
          
        
      ## TODO: Proper naming!!!
      ## TODO: Split up functions?
            
      ## Note: As long, as there are two conditional probabilities 
      ## and the corresponding unconditional probability, all can be calculated in a 2x2 table.
      ## However, this is redundant with the pathway over the frequencies:
      ## - as soon, as any frequency is given--may be an arbitrary N--a row or column can be calculated;
        ## This allows to calculate the col or row sums
        ## From these one can calculate the cell frequencies via the corresponding conditional ps!
      
      ## ANY frequency + appropriate probabilities will do!
      ## This accounts for using the frequency + probability algorithm and the frequency algorithm. 
      
    ##+++HERE+++##

    ## (2) Calculating frequencies from probabilities: ------
      ## Note: as long as there is one probability and one frequency in any row or column it can be calculated.
      
      ## Mapping:
        ## Within each row or column the other dimension maps 1 -> 4, 2 -> 5 in a 2x2 table. 
        ## More generally it maps according to cell_ix -> cell_ix + dim + 1  (dim - 1 + 2). 

  ## TODO: When to set N = 1 (or other arbitrary number)?

  ## (C) General consistency checks:
    ## TODO? Calculate the table in different ways and compare the results? 
        
        ## Potential ways of checkign: 
          ## - is_valid_prob_pair {riskyr} (passing tol!)
          ## - is_prob

  
}


```


```{r function_testing}
## (A) Frequency version:
calc_tab(ex_tab)
```


Goal: Devise an "escalation-schedule": In which order should frequencies, probabilities, and their mixture be calculated? 

## OLDER MATERIALS


## Confusion Matrix

|              | Condition |          |       |          |            
| ----------:  |:--------:|:--------:|:--------:|:--------:|              
| **Decision** | present (`TRUE`):      | absent (`FALSE`):     |     Sum:  |  (b) by decision: |  
| positive (`TRUE`):   | `hi`         | `fa`         | `dec.pos` | `PPV` = `hi`/`dec.pos` |
| negative (`FALSE`):  | `mi`         | `cr`         | `dec.neg` | `NPV` = `cr`/`dec.neg` |
|      Sum:    | `cond.true`  | `cond.false` |       `N` |         `prev` =  `cond.true`/`N`     |
| (a) by condition  | `sens` = `hi`/`cond.true` | `spec` = `cr`/`cond.false` | `ppod` = `dec.pos`/`N` |  `acc` = `dec.cor`/`N` = (`hi`+`cr`)/`N` |



## References

Links to related Wikipedia articles:

- [Confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix) (URL: https://en.wikipedia.org/wiki/Confusion_matrix)



## Contact

<!-- uni.kn logo and link to SPDS: -->  
<!-- ![](./inst/pix/uniKn_logo.png) --> 
<a href="https://www.spds.uni-konstanz.de/">
<img src = "../inst/pix/uniKn_logo.png" alt = "spds.uni.kn" style = "width: 280px; float: right; border:10;"/> 
<!--<img src = "../inst/pix/uniKn_logo_s.png" alt = "spds.uni.kn" style = "float: right; border:10;"/> --> 
</a>

We appreciate your feedback, comments, or questions. 

- Please report any `riskyr`-related issues at <https://github.com/hneth/riskyr/issues>.

- For general inquiries, please email us at <contact.riskyr@gmail.com>. 


## All `riskyr` Vignettes

<!-- riskyr logo: -->
<a href="https://github.com/hneth/riskyr">
<img src="../inst/pix/riskyr_cube.png" alt="riskyr" style="width: 125px; float: right; border:10;"/>
</a>

<!-- Index of vignettes: -->

| Nr.  | Vignette | Content    |        
| ---: |:---------|:-----------|
| A. | [User guide](A_user_guide.html) | Motivation and general instructions | 
| B. | [Data formats](B_data_formats.html) | Data formats: Frequencies and probabilities | 
| C. | [Confusion matrix](C_confusion_matrix.html) | Confusion matrix and accuracy metrics |
| D. | [Functional perspectives](D_functional_perspectives.html) | Adopting functional perspectives |
| E. | [Quick start primer](E_riskyr_primer.html) | Quick start primer |

<!-- eof. -->
